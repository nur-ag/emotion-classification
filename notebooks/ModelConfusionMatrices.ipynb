{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dill\n",
    "\n",
    "import torch\n",
    "\n",
    "# Monkey patch the method to enforce loading on CPU since we trained on CUDA\n",
    "base_load = torch.load\n",
    "torch.load = lambda f: base_load(f, map_location='cpu')\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../preprocessed/vent-split-robust-cache/test-cols.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cats = pd.read_csv('../preprocessed/category_names.csv')[['category_name', 'name']]\n",
    "\n",
    "top_cats = full_cats.category_name.unique()\n",
    "top_cats.sort()\n",
    "top_cats = {cat: i for i, cat in enumerate(top_cats)}\n",
    "\n",
    "cat_for = {row['name']: top_cats[row.category_name] for i, row in full_cats.iterrows()}\n",
    "\n",
    "emo_mapping = full_cats.name.unique()\n",
    "emo_mapping.sort()\n",
    "emo_mapping = {i: cat_for[name] for i, name in enumerate(emo_mapping)}\n",
    "\n",
    "df['category_index'] = [emo_mapping[emotion] for emotion in df.emotion_index.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_bert_lstm_hash = '0f3700bb5aa13110dc2f5cbedc09701f'\n",
    "vent_tfidf_logreg_hash = '1bc7b487f61026fdfefc8afb524589cf'\n",
    "\n",
    "experiment_hash = vent_bert_lstm_hash\n",
    "is_bert = experiment_hash == vent_bert_lstm_hash\n",
    "\n",
    "config = json.load(open(f'../output/Vent/replica-full/{experiment_hash}.json'))\n",
    "thresholds = np.asarray(config['results']['thresholds'][1])\n",
    "cats, extractor, model = dill.load(open(f'../models/Vent/{experiment_hash}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict:   0%|          | 0/3807 [00:00<?, ?it/s]/usr/local/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Predict:  43%|████▎     | 1628/3807 [11:23:01<14:45:32, 24.38s/it]"
     ]
    }
   ],
   "source": [
    "from utils.generators import SizedCallableWrapper, SizedBatchWrapper\n",
    "\n",
    "NUM_LABELS = len(thresholds)\n",
    "NUM_CATEGORIES = len(top_cats)\n",
    "NUM_SAMPLES = 1000000\n",
    "BATCH_SIZE = 256\n",
    "inputs = df.text.tolist()[:NUM_SAMPLES]\n",
    "labels = df.emotion_index.tolist()[:NUM_SAMPLES]\n",
    "\n",
    "input_batches = SizedBatchWrapper(inputs, batch_size=BATCH_SIZE)\n",
    "input_vectors = SizedCallableWrapper(input_batches, extractor)\n",
    "output = model.predict(input_vectors)\n",
    "output_labels = 1 * (output > thresholds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category-level classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluate import classification_report\n",
    "\n",
    "dataset_samples = len(output)\n",
    "category_output = np.zeros((len(output), NUM_CATEGORIES))\n",
    "\n",
    "for instance_index, label_index in zip(*np.nonzero(output_labels)):\n",
    "    category_index = emo_mapping[label_index]\n",
    "    category_output[instance_index, category_index] = 1\n",
    "\n",
    "category_truth = np.zeros((len(output), NUM_CATEGORIES))\n",
    "category_truth[np.arange(dataset_samples), df.category_index.tolist()[:dataset_samples]] = 1\n",
    "\n",
    "report = classification_report(category_truth, category_output, sorted(list(top_cats)))\n",
    "total_support = 0\n",
    "total_prec = 0\n",
    "total_rec = 0\n",
    "for label, stats in report['labels'].items():\n",
    "    p = stats['precision']\n",
    "    r = stats['recall']\n",
    "    f = stats['f1']\n",
    "    s = stats['support']\n",
    "    print('{}\\tPrecision: {:.3f}\\tRecall: {:.3f}\\tF1-score: {:.3f}\\tSupport: {:.0f}'.format(label, p, r, f, s))\n",
    "    total_rec += r * s\n",
    "    total_prec += p * s\n",
    "    total_support += s\n",
    "    \n",
    "total_prec /= total_support\n",
    "total_rec /= total_support\n",
    "print('')\n",
    "print('Mean macro F1-score: {:.2f}'.format(report['macro_f1']))\n",
    "print('Mean micro F1-score: {:.2f}'.format(report['micro_f1']))\n",
    "print('Mean micro Precision: {:.2f}'.format(total_prec))\n",
    "print('Mean micro Recall: {:.2f}'.format(total_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix & Hierarchical Clustering of label activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_confusion_matrix = np.zeros((NUM_LABELS, NUM_LABELS))\n",
    "\n",
    "for instance_index, label_index in zip(*np.nonzero(output_labels)):\n",
    "    actual_label = labels[instance_index]\n",
    "    label_confusion_matrix[actual_label, label_index] += 1\n",
    "\n",
    "for i, row in enumerate(label_confusion_matrix):\n",
    "    row_count = row.sum()\n",
    "    if row_count > 0:\n",
    "        label_confusion_matrix[i] /= row.sum()\n",
    "    \n",
    "label_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16), dpi=200)\n",
    "plt.matshow(label_confusion_matrix, fignum=0)\n",
    "plt.title('Actual vs Predicted Label Matrix')\n",
    "plt.xlabel('Predicted labels for comments under the given label.')\n",
    "plt.ylabel('User-provided labels.')\n",
    "plt.yticks(np.arange(NUM_LABELS), labels=cats)\n",
    "plt.xticks(np.arange(NUM_LABELS), labels=cats, rotation='vertical')\n",
    "fig.axes[0].xaxis.tick_top()\n",
    "fig.axes[0].xaxis.set_label_position('top') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, labels=cats, **kwargs)\n",
    "\n",
    "dend = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "dend = dend.fit(2 / (label_confusion_matrix + 1.0) - 1)\n",
    "\n",
    "plt.figure(figsize=(9, 2), dpi=240)\n",
    "plt.yticks([])\n",
    "plt.title('Actual vs Predicted Emotion Hierarchical Clustering')\n",
    "plot_dendrogram(dend, truncate_mode='level', p=88)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label confusion table & predictions\n",
    "\n",
    "Find the top 5 most chosen labels given every label and some sample predictions on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "', '.join([cats[x] for x in label_confusion_matrix.T.sum(axis=1).argsort()[::-1]])\n",
    "\n",
    "print('\\n'.join([f'{cats[i]}: {\", \".join([cats[l] for l in labels])}' \n",
    "                 for i, labels in enumerate(label_confusion_matrix.argsort()[:,::-1][:, :5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (', '.join([cats[idx] for idx in values[-5:]]) for values in output.argsort().tolist()[:100])\n",
    "\n",
    "for i, p in zip(inputs, predictions):\n",
    "    print(f'{p} -- {i}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
